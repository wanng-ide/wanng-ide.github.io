<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- Chrome, Firefox OS and Opera Status Bar Color -->
<meta name="theme-color" content="#FFFFFF">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link rel="stylesheet" type="text/css"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
<link rel="stylesheet" type="text/css" href="css/theme.css">
<link rel="stylesheet" type="text/css" href="css/notablog.css">
<!-- Favicon -->

  <link rel="shortcut icon" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F569682a6-68ca-45a2-9517-e517315772a3%2F20221008173023.jpg?table=collection&amp;id=9f6a1697-33c8-4423-aa25-8d6b3236f1ea">

<style>
  :root {
    font-size: 20px;
  }
</style>
  <title>随笔&nbsp;|&nbsp;王军杰 Wang Junjie</title>
  <meta property="og:type" content="blog">
  <meta property="og:title" content="随笔">
  
    <meta name="description" content="一些见解">
    <meta property="og:description" content="一些见解">
  
  
    <meta property="og:image" content="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0228da34-a6bc-4884-ab9a-187c8da199ac%2F%25E5%2586%2599%25E6%2596%2587%25E7%25AB%25A0.png?table=block&amp;id=02b0cfd3-9ad8-4622-9854-29dd8b754e3e">
  
  <style>
    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
  <a href="index.html">
    <div class="Navbar__Btn">
      
        <span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F569682a6-68ca-45a2-9517-e517315772a3%2F20221008173023.jpg?table=collection&amp;id=9f6a1697-33c8-4423-aa25-8d6b3236f1ea"></span>&nbsp;
      
      <span>Home</span>
    </div>
  </a>
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="resume.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F945bd6ad-aea7-4c49-807d-f3233e37529f%2Fheadhunting.png?table=block&amp;id=78648608-574f-4222-8fdb-dca2c23ab30e"></span>&nbsp;
          
          <span>简历 Resume</span>
        </div>
      </a>
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="publications.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffbcf1ef1-dd5e-4a54-953f-6ee736565062%2Fgraduation.png?table=block&amp;id=886cb69d-5cef-4ca4-a5a2-a15304705404"></span>&nbsp;
          
          <span>学术发表 Publications</span>
        </div>
      </a>
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="projects.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F098a6309-b031-4c05-a687-452fe6189088%2Fproject.png?table=block&amp;id=f4b13e35-ffa6-4c98-a144-277d8c4905f1"></span>&nbsp;
          
          <span>项目 Projects</span>
        </div>
      </a>
    
  
    
  
    
  
</nav>
  <header class="Header">
    
      <div class="Header__Cover">
        <img src="https://images.unsplash.com/photo-1577563908411-5077b6dc7624?ixlib=rb-4.0.3&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb">
      </div>
    
    <div class="Header__Spacer ">
    </div>
    
      <div class="Header__Icon">
        <span><img class="inline-img-icon" src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0228da34-a6bc-4884-ab9a-187c8da199ac%2F%25E5%2586%2599%25E6%2596%2587%25E7%25AB%25A0.png?table=block&amp;id=02b0cfd3-9ad8-4622-9854-29dd8b754e3e"></span>
      </div>
    
    <h1 class="Header__Title">随笔</h1>
    
      <div class="DateTagBar">
        
          <span class="DateTagBar__Item DateTagBar__Date">Posted on Sun, Dec 11, 2022</span>
        
        
          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--blue">
            <a href="tag/announcement.html">announcement</a>
          </span>
        
      </div>
    
  </header>
  <article id="https://www.notion.so/02b0cfd39ad84622985429dd8b754e3e" class="PageRoot"><div id="https://www.notion.so/c80299dcf830475c82e80c1f596c2c9a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">一些随笔</span></span></p></div><div id="https://www.notion.so/e0d919333dc04f0e87bda6a91f98c3bb" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h2 id="https://www.notion.so/4679b56d3c5c4a4ea9c56808fd319efe" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--2"><a class="Anchor" href="#https://www.notion.so/4679b56d3c5c4a4ea9c56808fd319efe"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">关于Compression for AGI</span></span></h2><div id="https://www.notion.so/cacd22d219914d2c8f12ae49cc51b513" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/3c2af52acb7a4712bb3f9c727f1cbad1" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">参考：</span></span></p></div><div id="https://www.notion.so/96b355d32b954d999049c66b7ba47242" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.youtube.com/watch?v=dO4TPJkeaaU">https://www.youtube.com/watch?v=dO4TPJkeaaU</a></span></span></p></div><div id="https://www.notion.so/5e04f265d3c849698bc0fcb358428d8f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://zhuanlan.zhihu.com/p/621201155">https://zhuanlan.zhihu.com/p/621201155</a></span></span></p></div><div id="https://www.notion.so/5ec5bb4d11f9468ca07acbf523975510" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/25f1aec253864f678aa010c4895e12e4" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">这里我简单的总结一下视频 中的看法。</span></span></p></div><div id="https://www.notion.so/8827a44059dc4daa8d3ed27302aa5fdb" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/6fd5e155d90247cc89518e5fddbda8ca" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">看法1：任务理解与描述长度的关系</strong></span><span class="SemanticString">
对完成某任务的有效方法的描述长度，反映了对该任务的理解深度。
</span></span></p></div><div id="https://www.notion.so/4225a17f380741af9339a98f1214ff58" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">例子：英文到中文的翻译
仅通过查字典的方法描述长度大，理解浅。加入语法、固定词组搭配等规则后，描述长度缩短，理解加深。</span></span></p></div><div id="https://www.notion.so/d75542751c2548cf973f7c9e258cf1c2" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F64182ed9-6b2d-4db9-a281-dfa010281805%2F2e7e92d2-bcea-49db-943e-b43751d25a33%2FUntitled.png?width=2138&amp;table=block&amp;id=d7554275-1c25-48cf-973f-7c9e258cf1c2"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F64182ed9-6b2d-4db9-a281-dfa010281805%2F2e7e92d2-bcea-49db-943e-b43751d25a33%2FUntitled.png?width=2138&amp;table=block&amp;id=d7554275-1c25-48cf-973f-7c9e258cf1c2" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/5719e72a49da43479248734ffb830f35" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">
这蕴含了：有效方法的最小描述长度代表了对任务的最优理解。</span></span></p></div><div id="https://www.notion.so/9adbfcc5992a4e4e99647f04c246b1ef" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">其实这是很容易理解的，因为我们从小的学习到的内容就是如此。比如物理学的公式是简洁的，但是可以描述复杂的自然现象。</span></span></p></div><div id="https://www.notion.so/01cd74d44c5641898f478244ec128d77" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/486d8fd1a90943ba88b0f8e434c6d224" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">看法2：AGI基础模型的目标</strong></span><span class="SemanticString">
AGI基础模型的目标不仅是对训练集的重建，更重要的是对训练集以外的信息进行最大限度的表示。</span></span></p></div><div id="https://www.notion.so/5a771168bfe84c45b43152f481ed39d0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">
压缩的目标是对训练数据所代表的真实世界信息能够最大程度的泛化表示。</span></span></p></div><div id="https://www.notion.so/f5625e925bde49148e61e692743cd64d" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F64182ed9-6b2d-4db9-a281-dfa010281805%2Ffc62edf0-0d5f-47cc-935c-483b7abe00a4%2FUntitled.png?width=2088&amp;table=block&amp;id=f5625e92-5bde-4914-8e61-e692743cd64d"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F64182ed9-6b2d-4db9-a281-dfa010281805%2Ffc62edf0-0d5f-47cc-935c-483b7abe00a4%2FUntitled.png?width=2088&amp;table=block&amp;id=f5625e92-5bde-4914-8e61-e692743cd64d" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/9968af9f685247bcbf5d264d69cbf6de" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">
AGI基础模型工作的总纲：明确目标、搜集尽可能多的有效数据，然后使用所有可能的无损压缩方式，从而得到对任务方法的最小描述长度。</span></span></p></div><div id="https://www.notion.so/60536ecb092a4a03b0ddeea13e80fca0" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/20f9d63e3d254e4db7904cf3ef13399a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">看法3：大语言模型和无损压缩</strong></span><span class="SemanticString">
大语言模型的理解能力（描述长度）是可量化的。
无损压缩的大小可以表示为对评估的生成模型的负对数似然与估计函数的最小描述长度之和。</span></span></p></div><div id="https://www.notion.so/3270a031cbaf4daaa59ab6aef30b36a2" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F64182ed9-6b2d-4db9-a281-dfa010281805%2F4fabdbc2-b22a-451d-84a4-6fea979c0d4c%2FUntitled.png?width=2072&amp;table=block&amp;id=3270a031-cbaf-4daa-a59a-b6aef30b36a2"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F64182ed9-6b2d-4db9-a281-dfa010281805%2F4fabdbc2-b22a-451d-84a4-6fea979c0d4c%2FUntitled.png?width=2072&amp;table=block&amp;id=3270a031-cbaf-4daa-a59a-b6aef30b36a2" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/977ce42e176748bf83ad12e2c0f3bfca" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">其实现在的大模型度量都是各有各的说法，但是或许loss这个指标呢，或者是压缩率这个指标，可以成为一种比较统一的度量衡。（实际上很多论文就是用这个方法度量LLM的）</span></span></p></div><div id="https://www.notion.so/0d160b1c6bc7434a961b0e8e153560a5" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/68b548231cd743e785b5dcc6b03561fc" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">例子：LLaMA 33B vs LLaMA 65B
两模型数据描述长度相同，但65B模型训练损失更低，因此65B是更好的压缩器。LLaMA 65B的压缩率为14倍。</span></span></p></div><div id="https://www.notion.so/4a978b58b02a4a05bb721b0cc3116ecd" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F64182ed9-6b2d-4db9-a281-dfa010281805%2Fecd84303-a280-4552-9010-b2125340fa97%2FUntitled.png?width=2097&amp;table=block&amp;id=4a978b58-b02a-4a05-bb72-1b0cc3116ecd"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F64182ed9-6b2d-4db9-a281-dfa010281805%2Fecd84303-a280-4552-9010-b2125340fa97%2FUntitled.png?width=2097&amp;table=block&amp;id=4a978b58-b02a-4a05-bb72-1b0cc3116ecd" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/f58cc9b554e34d9fabaea20ff231b00a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/9540ad4eaac242dbbdb349d3fbdd2d8a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">我的看法</strong></span></span></p></div><div id="https://www.notion.so/2fc6045a2c764be7beda7301d36fe68b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/aa475fe8fb7d4f738374f95590474da3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">其实压缩这个角度来看是非常合理的。</span></span></p></div><div id="https://www.notion.so/d236d496494a43f7aa38f8bdd038e846" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">假设，我们有这么一个语言模型：预测第一个词，是从整个“词表”中获取最有可能的词。我们可以假设这个词表的大小为30000。</span></span></p></div><div id="https://www.notion.so/f87970ff88cd43579ea56f4963c7f125" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">那么我可以建立两个序列，一个是LLM觉得最优可能的词的序列，一个是真实的序列。</span></span></p></div><div id="https://www.notion.so/11b37bc74d0143a7aa6444eadccb563d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">现在对于一句话“我今天很开心”。</span></span></p></div><div id="https://www.notion.so/194deb74ee84440284b6c22e8bd97695" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">LLM进行预测的行为是这样的，预测第一个词，会从30000个候选词进行排序，那么可能的序列为
[我：90%，你：8%，他：1%，…]，“我”在这个预测序列中的位置是第0个。</span></span></p></div><div id="https://www.notion.so/b2777d6fbf1e4cfc9ece02abf0157797" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">在预测第二个词的时候，LLM冲30000个词中预测的排序是[今：89%，后：7%，昨：1%，…]，那么，“今”在这个序列中的位置也是第0个。</span></span></p></div><div id="https://www.notion.so/b5decf350fe84ababcff4e8798b1b085" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">在预测第三个词的时候，LLM冲30000个词中预测的排序是[下：95%，天：2%，上：1%，…]，那么，“今”在这个序列中的位置也是第1个。</span></span></p></div><div id="https://www.notion.so/bfe7bb99cc134f6eb14d96183d8f6d11" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">以此类推，我们就得到了这么一个序列 [0,0,1,..]</span></span></p></div><div id="https://www.notion.so/b679db8abfc947458241a5951c6da280" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">假设这个模型预测和真实序列一致，也就是真实序列的位置对应着预测排序的位置永远是0，那么我们就可以得到 [0,0,0,0,0] 这个序列。</span></span></p></div><div id="https://www.notion.so/39ac803a93784a87851156f3c16076d5" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">假设预测错了，那就可能是 [0,1,0,3,0] 这样的序列了。</span></span></p></div><div id="https://www.notion.so/87aab167e3e54bc5963bfd5ae3780541" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/342a3b3632044e6b815a693dce740317" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">那么，假如预测错了，我们要如何纠正这个排序呢？其实也很简单，我们就对[0,1,0,3,0] 这样的序列应用一个压缩算法就好了，因为这里的0还是很多的（强大的LLM的第0个位置一般都是对的）。</span></span></p></div><div id="https://www.notion.so/99c58ac39eba4c9eafacd16dae3b370b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">这样也就可以理解，为什么[0,0,0,0,0] 这个序列是最好的了，因为，这不需要压缩算法，我只需要每次都取0就可以复现这个句子了。</span></span></p></div><div id="https://www.notion.so/d4a24a4d0e7c40b2afaf0ac530b00d6c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/2ccefc20903b4964a5b69746385a1676" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">这样理解压缩是不是就好理解多。 </span></span></p></div><div id="https://www.notion.so/4f2990bce6144025938e066bc55c2dc8" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/0aba38d4662c42579645249339540f22" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">不过这样的观点也就导致了</span></span></p></div><div id="https://www.notion.so/22abf97bb83e43c6a6b784cf7a10612b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">“只有被压缩的数据可以真实反映AGI，LLM才有可能实现AGI”</strong></span></span></p></div><div id="https://www.notion.so/33c0d99c4a004a0db0322e2d4c5944c9" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">也就是说，</span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">我们应该尽可能的抛弃掉“质量低”（没有智慧）的文本，而尽可能地使用“质量高”（有智慧）的文本。</strong></span></span></p></div><div id="https://www.notion.so/7f72297e27404572bd7d3741c704dafe" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">这样的话，我们可以从下列维度去思考如何引入更多“智慧”：</span></span></p></div><ol class="NumberedListWrapper"><li id="https://www.notion.so/53fdb70747d5415f9ff7b3d422bb76b8" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString">多场景：对话，思考，写作，代码等</span></span></li><li id="https://www.notion.so/dfa4cd9c837844fba68654c5b2332c40" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString">时效性：20世纪的智慧和21世纪是不一样的</span></span></li><li id="https://www.notion.so/ffcda12fd65e43b297f8257e8b53a278" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString">真实性和可靠性：我们要尽量去掉有误导性的话（当然，阴阳怪气也可以是智慧的一部分）</span></span></li><li id="https://www.notion.so/fcd3e3ca68764ac0b67aaa933ca075f9" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString">信息密度：一句诗可以包含巨大的信息量。</span></span></li><li id="https://www.notion.so/50b53fe6cd464fb59def5cbb3173ef6d" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString">复杂度：语料内部应该尽可能的复杂，同样的话语会导致同样的pattern，模型就学习的以偏概全了。</span></span></li><li id="https://www.notion.so/d1767c42ecd744e5bbc903787a689565" class="NumberedList" value="6"><span class="SemanticStringArray"><span class="SemanticString">数据形式：文本是只是真实世界的一种映射（不过文本确实是目前看来媒体里面最猛的，因为只有人类才会书写文字。而声音绘画等，有一些动物也是会的。ok这可能再展开就是，如何判断人类的智慧了。。）</span></span></li></ol><div id="https://www.notion.so/529feaaaf63b4640875b5ce58b9c4396" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/ccff65f5de1f47eb8d84380438ce7e02" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">而且这么一看，设计不同的prompt，本质上就是搭建了一个快速的“压缩代码”，又或者是让模型进行了一次不需要改变参数的Finetune。所以设计prompt可以如此简洁高效。</span></span></p></div></article>
  <footer class="Footer">
  <div>&copy; 王军杰 Wang Junjie 2022</div>
  <div>&centerdot;</div>
  <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
      rel="noopener noreferrer">Notablog</a>.
  </div>
</footer>
</body>

</html>